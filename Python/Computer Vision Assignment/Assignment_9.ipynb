{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff874907",
   "metadata": {},
   "source": "1. What are the advantages of a CNN for image classification over a completely linked DNN?"
  },
  {
   "cell_type": "markdown",
   "id": "7b122435",
   "metadata": {},
   "source": "2. Consider a CNN with three convolutional layers, each of which has three kernels, a stride of two, and SAME padding. The bottom layer generates 100 function maps, the middle layer 200, and the top layer 400. RGB images with a size of 200 x 300 pixels are used as input. How many criteria does the CNN have in total? How much RAM would this network need when making a single instance prediction if we're using 32-bit floats? What if you were to practice on a batch of 50 images?"
  },
  {
   "cell_type": "markdown",
   "id": "2ec10bc7",
   "metadata": {},
   "source": "3. What are five things you might do to fix the problem if your GPU runs out of memory while training a CNN?"
  },
  {
   "cell_type": "markdown",
   "id": "70ee1b16",
   "metadata": {},
   "source": "4. Why would you use a max pooling layer instead with a convolutional layer of the same stride?"
  },
  {
   "cell_type": "markdown",
   "id": "1f4acb9f",
   "metadata": {},
   "source": "5. When would a local response normalization layer be useful?"
  },
  {
   "cell_type": "markdown",
   "id": "a76b5a74",
   "metadata": {},
   "source": "6. In comparison to LeNet-5, what are the main innovations in AlexNet? What about GoogLeNet and ResNet's core innovations?"
  },
  {
   "cell_type": "markdown",
   "id": "aa66db67",
   "metadata": {},
   "source": "7. On MNIST, build your own CNN and strive to achieve the best possible accuracy."
  },
  {
   "cell_type": "markdown",
   "id": "02e070d6",
   "metadata": {},
   "source": "8. Using Inception v3 to classify broad images. a."
  },
  {
   "cell_type": "markdown",
   "id": "df1c473a",
   "metadata": {},
   "source": "Images of different animals can be downloaded. Load them in Python using the matplotlib.image.mpimg.imread() or scipy.misc.imread() functions, for example. Resize and/or crop them to 299 x 299 pixels, and make sure they only have three channels (RGB) and no transparency. The photos used to train the Inception model were preprocessed to have values ranging from -1.0 to 1.0, so make sure yours do as well."
  },
  {
   "cell_type": "markdown",
   "id": "16aef39b",
   "metadata": {},
   "source": "9. Large-scale image recognition using transfer learning."
  },
  {
   "cell_type": "markdown",
   "id": "df228499",
   "metadata": {},
   "source": "a. Make a training set of at least 100 images for each class. You might, for example, identify your own photos based on their position (beach, mountain, area, etc.) or use an existing dataset, such as the flowers dataset or MIT's places dataset (requires registration, and it is huge)."
  },
  {
   "cell_type": "markdown",
   "id": "6f2f7d6f",
   "metadata": {},
   "source": "b. Create a preprocessing phase that resizes and crops the image to 299 x 299 pixels while also adding some randomness for data augmentation."
  },
  {
   "cell_type": "markdown",
   "id": "eed59c2b",
   "metadata": {},
   "source": "c. Using the previously trained Inception v3 model, freeze all layers up to the bottleneck layer (the last layer before output layer) and replace output layer with  appropriate number of outputs for your new classification task (e.g., the flowers dataset has five mutually exclusive classes so the output layer must have five neurons and use softmax activation function)."
  },
  {
   "cell_type": "markdown",
   "id": "38e01c13",
   "metadata": {},
   "source": "d. Separate the data into two sets: a training and a test set. The training set is used to train the model, and the test set is used to evaluate it."
  },
  {
   "cell_type": "markdown",
   "id": "3c9c81fa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70aed12b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d44f417f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae7c9cc5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e03d544f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4dac33cb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58b0e892",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65b25ea1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8ddbf3d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38127c4d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdaf526e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2176414d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4626ed9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d7c9c46",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b26244e8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d966d2ea",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "921d745d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82ae2466",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}